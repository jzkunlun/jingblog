---
layout: post
title: Data Collection Tool...
published: true
categories: [Data, Scraping, Phantom.js]
---

I did data collection, or you call web scraping for many years. Initially, I use lynx and w3m and links ascii browsers with sed, awk(or gawk) and grep unix command. At that time, it works great, because there is no javascript or ajax call kind of thing. Web pages are most ascii text and some images. I felt i can collect anything i want from internet. 

Later on, i learnt perl which is called swissknife tool, particular WWW::Mechnism perl module which i used to did a lot data collection. About 2004, perl is phasing out, python is geting hot, in the meantime, ruby was born and has big momentum, there came new tool, scrapy from python and watir from ruby. At this time, ajax was comming and javascript was getting popular, all the tools seemed having limitations, I don't have confidence to say i can successfully scrapping anything i want from internet.  

Since i use Phantom.js, my confidence came back. I felt i can do anything i wantto collect.  



